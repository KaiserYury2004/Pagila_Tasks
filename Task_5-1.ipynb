{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Установка Spark сессии и подключение к конфигурационному файлу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['config.ini']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import configparser\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"PySpark_PostgreSQL\") \\\n",
    "    .config(\"spark.jars\", \"postgresql-42.7.3.jar\") \\\n",
    "    .getOrCreate()\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"config.ini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь происходит выгрузка базы данных из демо версии PostgrSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor = spark.read \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\",config['PostgreSQL']['url']) \\\n",
    "        .option(\"dbtable\", \"actor\") \\\n",
    "        .option(\"user\",config['PostgreSQL']['username'] ) \\\n",
    "        .option(\"password\", config['PostgreSQL']['password']) \\\n",
    "        .option(\"driver\", config['PostgreSQL']['driver']) \\\n",
    "        .load()\n",
    "address = spark.read \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\",config['PostgreSQL']['url']) \\\n",
    "        .option(\"dbtable\", \"address\") \\\n",
    "        .option(\"user\",config['PostgreSQL']['username'] ) \\\n",
    "        .option(\"password\", config['PostgreSQL']['password']) \\\n",
    "        .option(\"driver\", config['PostgreSQL']['driver']) \\\n",
    "        .load()\n",
    "category = spark.read \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\",config['PostgreSQL']['url']) \\\n",
    "        .option(\"dbtable\", \"category\") \\\n",
    "        .option(\"user\",config['PostgreSQL']['username'] ) \\\n",
    "        .option(\"password\", config['PostgreSQL']['password']) \\\n",
    "        .option(\"driver\", config['PostgreSQL']['driver']) \\\n",
    "        .load()\n",
    "city = spark.read \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\",config['PostgreSQL']['url']) \\\n",
    "        .option(\"dbtable\", \"city\") \\\n",
    "        .option(\"user\",config['PostgreSQL']['username'] ) \\\n",
    "        .option(\"password\", config['PostgreSQL']['password']) \\\n",
    "        .option(\"driver\", config['PostgreSQL']['driver']) \\\n",
    "        .load()\n",
    "country = spark.read \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\",config['PostgreSQL']['url']) \\\n",
    "        .option(\"dbtable\", \"country\") \\\n",
    "        .option(\"user\",config['PostgreSQL']['username'] ) \\\n",
    "        .option(\"password\", config['PostgreSQL']['password']) \\\n",
    "        .option(\"driver\", config['PostgreSQL']['driver']) \\\n",
    "        .load()\n",
    "film = spark.read \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\",config['PostgreSQL']['url']) \\\n",
    "        .option(\"dbtable\", \"film\") \\\n",
    "        .option(\"user\",config['PostgreSQL']['username'] ) \\\n",
    "        .option(\"password\", config['PostgreSQL']['password']) \\\n",
    "        .option(\"driver\", config['PostgreSQL']['driver']) \\\n",
    "        .load()\n",
    "customer = spark.read \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\",config['PostgreSQL']['url']) \\\n",
    "        .option(\"dbtable\", \"customer\") \\\n",
    "        .option(\"user\",config['PostgreSQL']['username'] ) \\\n",
    "        .option(\"password\", config['PostgreSQL']['password']) \\\n",
    "        .option(\"driver\", config['PostgreSQL']['driver']) \\\n",
    "        .load()\n",
    "film_actor = spark.read \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\",config['PostgreSQL']['url']) \\\n",
    "        .option(\"dbtable\", \"film_actor\") \\\n",
    "        .option(\"user\",config['PostgreSQL']['username'] ) \\\n",
    "        .option(\"password\", config['PostgreSQL']['password']) \\\n",
    "        .option(\"driver\", config['PostgreSQL']['driver']) \\\n",
    "        .load()\n",
    "film_category = spark.read \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\",config['PostgreSQL']['url']) \\\n",
    "        .option(\"dbtable\", \"film_category\") \\\n",
    "        .option(\"user\",config['PostgreSQL']['username'] ) \\\n",
    "        .option(\"password\", config['PostgreSQL']['password']) \\\n",
    "        .option(\"driver\", config['PostgreSQL']['driver']) \\\n",
    "        .load()\n",
    "inventory = spark.read \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\",config['PostgreSQL']['url']) \\\n",
    "        .option(\"dbtable\", \"inventory\") \\\n",
    "        .option(\"user\",config['PostgreSQL']['username'] ) \\\n",
    "        .option(\"password\", config['PostgreSQL']['password']) \\\n",
    "        .option(\"driver\", config['PostgreSQL']['driver']) \\\n",
    "        .load()\n",
    "language = spark.read \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\",config['PostgreSQL']['url']) \\\n",
    "        .option(\"dbtable\", \"language\") \\\n",
    "        .option(\"user\",config['PostgreSQL']['username'] ) \\\n",
    "        .option(\"password\", config['PostgreSQL']['password']) \\\n",
    "        .option(\"driver\", config['PostgreSQL']['driver']) \\\n",
    "        .load()\n",
    "payment = spark.read \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\",config['PostgreSQL']['url']) \\\n",
    "        .option(\"dbtable\", \"payment\") \\\n",
    "        .option(\"user\",config['PostgreSQL']['username'] ) \\\n",
    "        .option(\"password\", config['PostgreSQL']['password']) \\\n",
    "        .option(\"driver\", config['PostgreSQL']['driver']) \\\n",
    "        .load()\n",
    "rental = spark.read \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\",config['PostgreSQL']['url']) \\\n",
    "        .option(\"dbtable\", \"rental\") \\\n",
    "        .option(\"user\",config['PostgreSQL']['username'] ) \\\n",
    "        .option(\"password\", config['PostgreSQL']['password']) \\\n",
    "        .option(\"driver\", config['PostgreSQL']['driver']) \\\n",
    "        .load()\n",
    "staff = spark.read \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\",config['PostgreSQL']['url']) \\\n",
    "        .option(\"dbtable\", \"staff\") \\\n",
    "        .option(\"user\",config['PostgreSQL']['username'] ) \\\n",
    "        .option(\"password\", config['PostgreSQL']['password']) \\\n",
    "        .option(\"driver\", config['PostgreSQL']['driver']) \\\n",
    "        .load()\n",
    "store = spark.read \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .option(\"url\",config['PostgreSQL']['url']) \\\n",
    "        .option(\"dbtable\", \"store\") \\\n",
    "        .option(\"user\",config['PostgreSQL']['username'] ) \\\n",
    "        .option(\"password\", config['PostgreSQL']['password']) \\\n",
    "        .option(\"driver\", config['PostgreSQL']['driver']) \\\n",
    "        .load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№1.Вывести количество фильмов в каждой категории, отсортировать по убыванию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+---------------+\n",
      "|category_id|       name|Count_Of_Movies|\n",
      "+-----------+-----------+---------------+\n",
      "|          7|      Drama|            152|\n",
      "|         12|      Music|            152|\n",
      "|         16|     Travel|            151|\n",
      "|          3|   Children|            150|\n",
      "|         10|      Games|            150|\n",
      "|          9|    Foreign|            150|\n",
      "|         14|     Sci-Fi|            149|\n",
      "|          1|     Action|            149|\n",
      "|          2|  Animation|            148|\n",
      "|          4|   Classics|            147|\n",
      "|          8|     Family|            147|\n",
      "|         13|        New|            147|\n",
      "|          6|Documentary|            145|\n",
      "|         15|     Sports|            145|\n",
      "|          5|     Comedy|            143|\n",
      "|         11|     Horror|            142|\n",
      "+-----------+-----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count\n",
    "result_1 = category \\\n",
    ".join(film_category, category.category_id == film_category.category_id) \\\n",
    ".join(film, film_category.film_id == film.film_id) \\\n",
    ".groupBy(category.category_id, category.name) \\\n",
    ".agg(count(film.film_id).alias(\"Count_Of_Movies\")) \\\n",
    ".orderBy(\"Count_Of_Movies\", ascending=False)\n",
    "result_1.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№2.Вывести 10 актеров, чьи фильмы большего всего арендовали, отсортировать по убыванию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----------+---------------+\n",
      "|actor_id|first_name|  last_name|Count_Of_Rental|\n",
      "+--------+----------+-----------+---------------+\n",
      "|     107|      GINA|  DEGENERES|            753|\n",
      "|     181|   MATTHEW|     CARREY|            678|\n",
      "|     198|      MARY|     KEITEL|            674|\n",
      "|     144|    ANGELA|WITHERSPOON|            654|\n",
      "|     102|    WALTER|       TORN|            640|\n",
      "|      60|     HENRY|      BERRY|            612|\n",
      "|     150|     JAYNE|      NOLTE|            611|\n",
      "|      37|       VAL|     BOLGER|            605|\n",
      "|      23|    SANDRA|     KILMER|            604|\n",
      "|      90|      SEAN|    GUINESS|            599|\n",
      "+--------+----------+-----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_2 = actor \\\n",
    ".join(film_actor, actor.actor_id == film_actor.actor_id) \\\n",
    ".join(inventory, film_actor.film_id == inventory.film_id) \\\n",
    ".join(rental , inventory.inventory_id==rental.inventory_id)\\\n",
    ".groupBy(actor.actor_id, actor.first_name,actor.last_name) \\\n",
    ".agg(count(rental.rental_id).alias(\"Count_Of_Rental\")) \\\n",
    ".orderBy(\"Count_Of_Rental\", ascending=False)\\\n",
    ".limit(10)\n",
    "result_2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№3.Вывести категорию фильмов, на которую потратили больше всего денег."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- payment_id: integer (nullable = true)\n",
      " |-- customer_id: integer (nullable = true)\n",
      " |-- staff_id: integer (nullable = true)\n",
      " |-- rental_id: integer (nullable = true)\n",
      " |-- amount: decimal(5,2) (nullable = true)\n",
      " |-- payment_date: timestamp (nullable = true)\n",
      "\n",
      "+-----------+------+-------------+\n",
      "|category_id|  name|SpendedOnFilm|\n",
      "+-----------+------+-------------+\n",
      "|          5|Comedy|      9181.93|\n",
      "+-----------+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum\n",
    "result_3=category \\\n",
    ".join(film_category,category.category_id==film_category.category_id)\\\n",
    ".join(inventory,film_category.film_id==inventory.film_id)\\\n",
    ".join(rental,inventory.inventory_id==rental.inventory_id)\\\n",
    ".join(payment,rental.rental_id==payment.rental_id)\\\n",
    ".groupBy(category.category_id,category.name)\\\n",
    ".agg(sum(payment.amount).alias(\"SpendedOnFilm\"))\\\n",
    ".orderBy(\"SpendedOnFilm\",descending=True)\\\n",
    ".limit(1)\n",
    "result_3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№4.Вывести названия фильмов, которых нет в inventory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               title|\n",
      "+--------------------+\n",
      "|       RAINBOW SHOCK|\n",
      "|           GUMP DATE|\n",
      "|         HOCUS FRIDA|\n",
      "|    TREASURE COMMAND|\n",
      "| CHINATOWN GLADIATOR|\n",
      "|        WALLS ARTIST|\n",
      "|      ARGONAUTS TOWN|\n",
      "|       PSYCHO SHRUNK|\n",
      "|   FIREHOUSE VIETNAM|\n",
      "|DELIVERANCE MULHO...|\n",
      "|       ROOF CHAMPION|\n",
      "|        TADPOLE PARK|\n",
      "|         APOLLO TEEN|\n",
      "|       HATE HANDICAP|\n",
      "|       PEARL DESTINY|\n",
      "|COMMANDMENTS EXPRESS|\n",
      "|        VOLUME HOUSE|\n",
      "|     CROWDS TELEMARK|\n",
      "|   RAIDERS ANTITRUST|\n",
      "|    KILL BROTHERHOOD|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --Вывести названия фильмов, \n",
    "# --которых нет в inventory. \n",
    "# --Написать запрос без использования оператора IN.\n",
    "# SELECT f.title\n",
    "# FROM film f\n",
    "# EXCEPT\n",
    "# SELECT f.title\n",
    "# FROM inventory inv \n",
    "# JOIN film f ON inv.film_id=f.film_id\n",
    "result_4=film.select(film.title)\\\n",
    ".subtract(inventory.join(film,inventory.film_id==film.film_id).select(film.title))\n",
    "result_4.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#5.Вывести топ 3 актеров, которые больше всего появлялись в фильмах в категории “Children”. Если у нескольких актеров одинаковое кол-во фильмов, вывести всех.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------+-------+-----+\n",
      "|actor_id|          Person|Counter|place|\n",
      "+--------+----------------+-------+-----+\n",
      "|     105|    SIDNEY CROWE|      9|    1|\n",
      "|     133|    RICHARD PENN|      9|    1|\n",
      "|     139|    EWAN GOODING|      9|    1|\n",
      "|      56|      DAN HARRIS|      8|    2|\n",
      "|     149|  RUSSELL TEMPLE|      8|    2|\n",
      "|      66|      MARY TANDY|      8|    2|\n",
      "|      29|      ALEC WAYNE|      8|    2|\n",
      "|     145|       KIM ALLEN|      8|    2|\n",
      "|     181|  MATTHEW CARREY|      8|    2|\n",
      "|     131|    JANE JACKMAN|      8|    2|\n",
      "|      87|    SPENCER PECK|      8|    2|\n",
      "|     142|      JADA RYDER|      8|    2|\n",
      "|      84|      JAMES PITT|      7|    3|\n",
      "|     123|  JULIANNE DENCH|      7|    3|\n",
      "|      34|  AUDREY OLIVIER|      7|    3|\n",
      "|      96|     GENE WILLIS|      7|    3|\n",
      "|      94|    KENNETH TORN|      7|    3|\n",
      "|      95|  DARYL WAHLBERG|      7|    3|\n",
      "|      85|MINNIE ZELLWEGER|      7|    3|\n",
      "|      65|   ANGELA HUDSON|      7|    3|\n",
      "+--------+----------------+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, concat_ws, count, dense_rank\n",
    "from pyspark.sql.window import Window\n",
    "joined_df = actor.alias('a') \\\n",
    "    .join(film_actor.alias('fa'), col('a.actor_id') == col('fa.actor_id')) \\\n",
    "    .join(film_category.alias('fc'), col('fa.film_id') == col('fc.film_id')) \\\n",
    "    .join(category.alias('ca'), col('fc.category_id') == col('ca.category_id')) \\\n",
    "    .filter(col('ca.name') == 'Children')\n",
    "count_df = joined_df \\\n",
    "    .withColumn(\"Person\", concat_ws(\" \", col(\"a.first_name\"), col(\"a.last_name\"))) \\\n",
    "    .groupBy(col(\"a.actor_id\"), col(\"Person\")) \\\n",
    "    .agg(count(col(\"fc.film_id\")).alias(\"Counter\"))\n",
    "window_spec = Window.orderBy(col(\"Counter\").desc())\n",
    "ranked_df = count_df.withColumn(\"place\", dense_rank().over(window_spec))\n",
    "result_5 = ranked_df.filter(col(\"place\") <= 3).orderBy(col(\"Counter\").desc())\n",
    "result_5.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№6.Вывести города с количеством активных и неактивных клиентов (активный — customer.active = 1). Отсортировать по количеству неактивных клиентов по убыванию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------+-------+\n",
      "|              city|Actives|Pasives|\n",
      "+------------------+-------+-------+\n",
      "|          Uluberia|      0|      1|\n",
      "|         Najafabad|      0|      1|\n",
      "|         Pingxiang|      0|      1|\n",
      "|          Xiangfan|      0|      1|\n",
      "|        Kumbakonam|      0|      1|\n",
      "|       Szkesfehrvr|      0|      1|\n",
      "|  Charlotte Amalie|      0|      1|\n",
      "|            Kamyin|      0|      1|\n",
      "|            Daxian|      0|      1|\n",
      "|     Coatzacoalcos|      0|      1|\n",
      "|           Wroclaw|      0|      1|\n",
      "|            Ktahya|      0|      1|\n",
      "|            Amroha|      0|      1|\n",
      "|   Southend-on-Sea|      0|      1|\n",
      "|           Bat Yam|      0|      1|\n",
      "|          Fengshan|      1|      0|\n",
      "|A Corua (La Corua)|      1|      0|\n",
      "|           El Alto|      1|      0|\n",
      "|              Linz|      1|      0|\n",
      "|          Myingyan|      1|      0|\n",
      "+------------------+-------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, count, when,unix_timestamp\n",
    "result_6 = city \\\n",
    "    .join(address, city.city_id == address.city_id) \\\n",
    "    .join(customer, address.address_id == customer.address_id, \"right\")\\\n",
    "    .groupBy(city.city)\\\n",
    "    .agg(count(when(col(\"active\") == 1, 1)).alias(\"Actives\"),count(when(col(\"active\") == 0, 1)).alias(\"Pasives\"))\\\n",
    "    .orderBy(col(\"Pasives\").desc())\n",
    "result_6.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "№7.Вывести категорию фильмов, у которой самое большое кол-во часов суммарной аренды в городах (customer.address_id в этом city), и которые начинаются на букву “a”. Тоже самое сделать для городов в которых есть символ “-”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+-------+\n",
      "|category_id| name| Amount|\n",
      "+-----------+-----+-------+\n",
      "|         12|Music|4096800|\n",
      "+-----------+-----+-------+\n",
      "\n",
      "+-----------+--------+--------+\n",
      "|category_id|    name|  Amount|\n",
      "+-----------+--------+--------+\n",
      "|          3|Children|34890840|\n",
      "+-----------+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_7_a=city \\\n",
    "    .join(address, city.city_id == address.city_id) \\\n",
    "    .join(customer, address.address_id == customer.address_id) \\\n",
    "    .join(rental, customer.customer_id == rental.customer_id) \\\n",
    "    .join(inventory,rental.inventory_id  == inventory.inventory_id) \\\n",
    "    .join(film_category, inventory.film_id == film_category.film_id) \\\n",
    "    .join(category, film_category.category_id == category.category_id) \\\n",
    "    .filter(city.city.startswith('a'))\\\n",
    "    .withColumn(\"rental_duration\", (unix_timestamp(rental.return_date) - unix_timestamp(rental.rental_date))) \\\n",
    "    .groupBy(category.category_id,category.name) \\\n",
    "    .agg(sum(\"rental_duration\").alias(\"Amount\")) \\\n",
    "    .orderBy(\"Amount\") \\\n",
    "    .limit(1)\n",
    "result_7_a.show()\n",
    "result_7__=city \\\n",
    "    .join(address, city.city_id == address.city_id) \\\n",
    "    .join(customer, address.address_id == customer.address_id) \\\n",
    "    .join(rental, customer.customer_id == rental.customer_id) \\\n",
    "    .join(inventory,rental.inventory_id  == inventory.inventory_id) \\\n",
    "    .join(film_category, inventory.film_id == film_category.film_id) \\\n",
    "    .join(category, film_category.category_id == category.category_id) \\\n",
    "    .filter(city.city.like('%-%'))\\\n",
    "    .withColumn(\"rental_duration\", (unix_timestamp(rental.return_date) - unix_timestamp(rental.rental_date))) \\\n",
    "    .groupBy(category.category_id,category.name) \\\n",
    "    .agg(sum(\"rental_duration\").alias(\"Amount\")) \\\n",
    "    .orderBy(col(\"Amount\")) \\\n",
    "    .limit(1)\n",
    "result_7__.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
